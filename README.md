# 🤖 AI/ML 포트폴리오 (AI/ML Portfolio)

안녕하세요! 이 저장소는 저의 인공지능 및 머신러닝 프로젝트들을 모아놓은 포트폴리오입니다. 각 프로젝트는 문제 정의부터 데이터 처리, 모델링, 그리고 결과 분석까지의 전 과정을 담고 있습니다.

---

### 📚 목차 (Table of Contents)
1. [**Project 1:** 농산물 가격 예측 모델](#project-1-농산물-가격-예측-모델)
2. [**Project 2:** 베이즈 네트워크를 이용한 확률적 추론](#project-2-베이즈-네트워크를-이용한-확률적-추론-및-상태-예측)
3. [**Project 3:** 딥러닝 기반 미세 객체 탐지](#project-3-딥러닝-기반-미세-객체-탐지)
4. [**Project 4:** 데이터베이스 관리 및 고급 SQL](#project-4-데이터베이스-관리-및-고급-sql)
5. [**Project 5:** 대규모 분산 데이터 처리](#project-5-대규모-분산-데이터-처리-with-spark--flink)

---

## **Project 1: 농산물 가격 예측 모델**
(...생략...)

---

## **Project 2: 베이즈 네트워크를 이용한 확률적 추론 및 상태 예측**
(...생략...)

---

## **Project 3: 딥러닝 기반 미세 객체 탐지**
(...생략...)

---

## **Project 4: 데이터베이스 관리 및 고급 SQL**
(...생략...)

---

## **Project 5: 대규모 분산 데이터 처리 with Spark & Flink**
### **Apache Spark 및 Flink를 활용한 대용량 데이터 분석 및 처리**

#### **1. 프로젝트 개요 (Overview)**
이 프로젝트는 대규모 데이터 분석을 위한 필수 기술인 **분산 컴퓨팅 프레임워크** 활용 능력을 보여줍니다. 학부 '대규모 데이터 분석' LAB 과정에서 **Apache Spark**와 **Apache Flink**를 사용하여 대용량 데이터를 처리하고 분석하는 다양한 과제를 수행했습니다. 이를 통해 MapReduce 패러다임에 대한 깊은 이해와 실질적인 데이터 엔지니어링 역량을 함양했습니다.

➡️ **[전체 실험 과정 및 결과 리포트 보기](./project5-assets/BigData_Lab_Report.pdf)**
*(학업 윤리 준수를 위해 전체 소스 코드는 공개하지 않으며, 요청 시 비공개 저장소를 통해 공유 가능합니다.)*

#### **2. 주요 기술 스택 (Tech Stack)**
- **Frameworks**: `Apache Spark`, `Apache Flink`, `Hadoop MapReduce`
- **Language**: `Java`
- **Infrastructure**: `Hadoop (HDFS)`

#### **3. 세부 과제 및 성과**

**Part 1: GitHub 데이터 분석 (Spark)**
- **과제**: 대용량 CSV 데이터를 분석하여, 프로그래밍 언어별 (1) 저장소 수와 (2) 가장 많은 스타(star)를 받은 저장소를 집계 및 정렬했습니다.
- **주요 로직**: `mapToPair`를 이용해 Key-Value 쌍을 생성하고, `reduceByKey`로 언어별 데이터를 그룹화하여 저장소 수를 합산하고 스타 수를 비교하는 로직을 구현했습니다.
- **성과**: 대용량 텍스트 데이터에 대한 분산 집계 및 정렬 처리 능력을 증명했습니다.
`[여기에 GitHub 분석 결과 스크린샷을 삽입하세요]`

**Part 2: 그래프 내 삼각형 구조 탐색 (Spark)**
- **과제**: 특허 인용 관계 그래프 데이터에서 **길이 3의 비방향성 사이클(삼각형 구조)**의 총 개수를 계산했습니다.
- **주요 로직**: 여러 단계의 `map`, `join`, `reduce` 연산을 통해 인접 리스트를 생성하고, 친구의 친구 관계를 탐색하여 삼각형 구조를 찾아내는 알고리즘을 분산 환경에 맞게 설계했습니다.
- **성과**: 복잡한 그래프 알고리즘을 분산 처리 패러다임에 맞게 구현하는 문제 해결 능력을 보여줍니다.

**Part 3: 방화벽 로그 분석 (Spark)**
- **과제**: IP 추적 로그와 차단 로그라는 두 개의 다른 데이터 소스를 결합하여, 차단된 IP의 활동 내역을 추출하고 가장 많은 활동을 보인 IP 주소를 집계했습니다.
- **주요 로직**: 각 로그 파일을 RDD로 변환한 후, `join` 연산을 통해 두 데이터 소스를 결합하고 `filter`를 통해 'Blocked' 상태의 로그만 추출했습니다.
- **성과**: 분산 환경에서의 데이터 조인(Join), 필터링, 집계 등 데이터 파이프라인의 핵심 연산 능력을 증명했습니다.
